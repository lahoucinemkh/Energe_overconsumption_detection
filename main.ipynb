{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c037489",
   "metadata": {
    "id": "7c037489"
   },
   "source": [
    "# Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec69a2e",
   "metadata": {
    "id": "eec69a2e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import xlsxwriter\n",
    "from pandas import ExcelFile\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import os\n",
    "import statistics\n",
    "from dateutil.parser import parse\n",
    "import math\n",
    "import calendar\n",
    "from sklearn.cluster import DBSCAN\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf06a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle à partir du fichier picklé\n",
    "loaded_model = joblib.load(\"svm_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c50da77",
   "metadata": {
    "id": "6c50da77"
   },
   "source": [
    "# Création de deux fonctions utilisables dans l'importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa4ccad",
   "metadata": {
    "id": "dfa4ccad"
   },
   "outputs": [],
   "source": [
    "\n",
    "def toZero(x):\n",
    "    try:\n",
    "        converted_value = int(x)\n",
    "    except ValueError:\n",
    "        converted_value = 0\n",
    "    return converted_value\n",
    "\n",
    "def findDay(date):\n",
    "    day, month, year = (int(i) for i in date.split('/'))\n",
    "    dayNumber = calendar.weekday(year, month, day)\n",
    "    return dayNumber\n",
    "\n",
    "def arrondir_multiple_de_5(nombre):\n",
    "    multiple_de_5 = round(nombre / 5) * 5\n",
    "    return multiple_de_5\n",
    "\n",
    "def process_data(df_Fusion, seuil):\n",
    "    groupe = 0\n",
    "    df_Fusion['Groupe'] = 0\n",
    "\n",
    "    for index, row in df_Fusion.iterrows():\n",
    "        if index == 0:\n",
    "            df_Fusion.at[index, 'Groupe'] = groupe\n",
    "        else:\n",
    "            diff = abs(row['Talon surconso identifie'] - df_Fusion.at[index - 1, 'Talon surconso identifie'])\n",
    "            if diff <= seuil:\n",
    "                df_Fusion.at[index, 'Groupe'] = groupe\n",
    "            else:\n",
    "                groupe += 1\n",
    "                df_Fusion.at[index, 'Groupe'] = groupe\n",
    "\n",
    "    df_simplified = df_Fusion.groupby(['Groupe', 'Début surconsommation', 'Fin surconsommation']).agg({\n",
    "        'Code': 'first',  # Include the 'Code' column from the original dataframe\n",
    "        'Energie': 'first',  # Include the 'Energie' column from the original dataframe\n",
    "        'heure ouverture': 'first',  # Include the 'heure ouverture' column from the original dataframe\n",
    "        'heure fermetur': 'first',  # Include the 'heure fermetur' column from the original dataframe\n",
    "        'TalonRef': 'first',  # Include the 'TalonRef' column from the original dataframe\n",
    "        'Début surconsommation': 'first',\n",
    "        'Fin surconsommation': 'first',\n",
    "        'Talon surconso identifie': 'mean',\n",
    "        'impact': 'first',  # Include the 'impact' column from the original dataframe\n",
    "        'NbrHeures': 'sum',\n",
    "        'NbrNuits': 'first',  # Include the 'NbrNuits' column from the original dataframe\n",
    "        'Impact conso (kWh)': 'first',  # Include the 'Impact conso (kWh)' column from the original dataframe\n",
    "        '% Surconso': 'first',  # Include the '% Surconso' column from the original dataframe\n",
    "        \"Période d'alerte\": 'first',  # Include the \"Période d'alerte\" column from the original dataframe\n",
    "        'Pourcentage de précision': 'first'  # Include the 'Pourcentage de précision' column from the original dataframe\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "    return df_simplified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4d9bb8",
   "metadata": {
    "id": "6c4d9bb8"
   },
   "source": [
    "# Création de l'algorithme de machine learning personnalisé que nous allons utiliser dans la fusion des heures de surconsommation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1380853",
   "metadata": {
    "id": "c1380853"
   },
   "source": [
    "# Cet algorithme est un algorithme de clustering non supervisé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b558e95",
   "metadata": {
    "id": "6b558e95"
   },
   "source": [
    "# Il prend en compte la successivité des heures et une marge de surconsommation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0c66db",
   "metadata": {
    "id": "df0c66db"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "\n",
    "class TimeMarginClustering(BaseEstimator, ClusterMixin):\n",
    "    def __init__(self, time_margin=1, value_margin=20):\n",
    "        self.time_margin = time_margin\n",
    "        self.value_margin = value_margin\n",
    "        self.labels_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Sort the data based on the time column (column 0)\n",
    "        sorted_indices = np.argsort(X[:, 0])\n",
    "        sorted_X = X[sorted_indices]\n",
    "\n",
    "        # Initialize variables for clustering\n",
    "        cluster_labels = np.zeros(len(X), dtype=int)\n",
    "        current_cluster = 0\n",
    "        prev_time = sorted_X[0, 0]\n",
    "        prev_value = sorted_X[0, 1]\n",
    "\n",
    "        # Iterate over the sorted data and assign cluster labels\n",
    "        for i in range(len(sorted_X)):\n",
    "            time = sorted_X[i, 0]\n",
    "            value = sorted_X[i, 1]\n",
    "\n",
    "            # Check if the time difference exceeds the time margin\n",
    "            time_diff = time - prev_time\n",
    "            if time_diff > self.time_margin:\n",
    "                current_cluster += 1\n",
    "\n",
    "            # Check if the value difference exceeds the value margin\n",
    "            value_diff = abs(value - prev_value)\n",
    "            if time_diff <= self.time_margin and value_diff > self.value_margin:\n",
    "                current_cluster += 1\n",
    "\n",
    "            # Assign the cluster label\n",
    "            cluster_labels[i] = current_cluster\n",
    "\n",
    "            # Update previous time and value\n",
    "            prev_time = time\n",
    "            prev_value = value\n",
    "\n",
    "        # Assign the cluster labels to the algorithm's attribute\n",
    "        self.labels_ = cluster_labels\n",
    "        return self\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        self.fit(X)\n",
    "        return self.labels_\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b58422",
   "metadata": {
    "id": "90b58422"
   },
   "source": [
    "# Importation des données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3cb604",
   "metadata": {
    "id": "2d3cb604"
   },
   "source": [
    "# Prétraitement des données (nettoyage des données)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfcb5cb",
   "metadata": {
    "id": "3cfcb5cb"
   },
   "source": [
    "# La détection de la surconsommation pour les nuits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76d40b",
   "metadata": {
    "id": "7a76d40b"
   },
   "source": [
    "# L'appel et l'application de l'algorithme de fusion des heures pour les nuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e9d8ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91e9d8ec",
    "outputId": "a24c9b5b-d037-4e99-f5d7-f9ab4cabb965"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lahoucine\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Both a converter and dtype were specified for column Real Consumption (kWh) - only the converter will be used.\n",
      "  return func(*args, **kwargs)\n",
      "C:\\Users\\Lahoucine\\AppData\\Local\\Temp\\ipykernel_13368\\3107651127.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['Date'] = pd.to_datetime(df3['Date'], format='%Y-%m-%d')\n",
      "C:\\Users\\Lahoucine\\AppData\\Local\\Temp\\ipykernel_13368\\3107651127.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['Time'] = pd.to_datetime(df3['Time'], format='%H:%M:%S')\n",
      "C:\\Users\\Lahoucine\\AppData\\Local\\Temp\\ipykernel_13368\\3107651127.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['DateTime'] = df3['Date'] + pd.to_timedelta(df3['Time'].dt.strftime('%H:%M:%S'))\n",
      "C:\\Users\\Lahoucine\\AppData\\Local\\Temp\\ipykernel_13368\\3107651127.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  donnees_filtrees['Difference'] = donnees_filtrees['Real Consumption (kWh)'] - talon_consommation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "l'analyse de site : {} MO0157\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[23 64]\n",
      " [24 62]\n",
      " [25 62]\n",
      " [26 55]\n",
      " [27 55]\n",
      " [28 60]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.datetime64' object has no attribute 'to_pydatetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m Energie\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElectricité\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    132\u001b[0m TalonRef_list\u001b[38;5;241m.\u001b[39mappend(talon_consommation)\n\u001b[1;32m--> 133\u001b[0m date1 \u001b[38;5;241m=\u001b[39m \u001b[43mdates_uniques\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydatetime\u001b[49m()\u001b[38;5;241m.\u001b[39mdate()\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m#date1 = datetime.datetime.strptime(date1, '%Y-%m-%d').date()\u001b[39;00m\n\u001b[0;32m    135\u001b[0m Date1_list\u001b[38;5;241m.\u001b[39mappend(date1)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.datetime64' object has no attribute 'to_pydatetime'"
     ]
    }
   ],
   "source": [
    "writer = pd.ExcelWriter('suivi_9_sites.xlsx', engine='xlsxwriter')\n",
    "\n",
    "Code_list=[]\n",
    "TalonRef_list=[]\n",
    "Date1_list=[]\n",
    "Date2_list=[]\n",
    "heurev_list=[]\n",
    "heuref_list=[]\n",
    "NbrHeure_list=[]\n",
    "defrence_list=[]\n",
    "surconso_identifie=[]\n",
    "Energie=[]\n",
    "Marge_list=[]\n",
    "\n",
    "\n",
    "\n",
    "# Charger les données du fichier CSV\n",
    "df = pd.read_csv('data.csv', sep=',', parse_dates=True, dtype={\"Date\":\"str\",\"Time\":\"str\",\"salesforceName\":\"str\",\"siteName\":\"str\",\"Real Consumption (kWh)\":\"int64\" , \"TalonRef\":\"int64\" , \"Heure Ouverture\":\"int64\" , \"Heure Fermeture\":\"int64\" , \"Ouverture dim\":\"str\" , \"Margin\":\"int64\"},converters={'Real Consumption (kWh)':toZero},encoding=\"utf-8-sig\")\n",
    "# Filtrer les données pour l'entreprise spécifiée\n",
    "#print(df.columns)\n",
    "for code in df[\"salesforceName\"].unique():\n",
    "    df2 = df[df[\"salesforceName\"] == code]\n",
    "\n",
    "    # Sélectionner les colonnes pertinentes (Date, Time, Real Consumption (kWh) , talont , ouverture , fermeture)\n",
    "    df3 = df2[['Date', 'Time', 'Real Consumption (kWh)',\"TalonRef\" , \"Heure Ouverture\" , \"Heure Fermeture\" , \"Margin\"]]\n",
    "\n",
    "    # Convertir la colonne 'Date' en type datetime avec le format approprié\n",
    "    df3['Date'] = pd.to_datetime(df3['Date'], format='%Y-%m-%d')\n",
    "\n",
    "    # Convertir la colonne 'Time' en type timedelta\n",
    "    df3['Time'] = pd.to_datetime(df3['Time'], format='%H:%M:%S')\n",
    "\n",
    "    # Combiner les colonnes 'Date' et 'Time' en une seule colonne de type datetime\n",
    "    df3['DateTime'] = df3['Date'] + pd.to_timedelta(df3['Time'].dt.strftime('%H:%M:%S'))\n",
    "\n",
    "    # Définition des heures d'ouverture et de fermeture de l'entreprise\n",
    "    heure_ouverture = df3[\"Heure Ouverture\"].iloc[0]\n",
    "    heure_fermeture = df3[\"Heure Fermeture\"].iloc[0]+1\n",
    "\n",
    "    # Définition du talon de consommation\n",
    "    talon_consommation = df3[\"TalonRef\"].iloc[0]\n",
    "    marge=df3[\"Margin\"].iloc[0]\n",
    "\n",
    "    # Filtrer les données pour les heures en dehors des heures d'ouverture de l'entreprise\n",
    "    if heure_fermeture == 0:\n",
    "        donnees_filtrees = df3[df3['DateTime'].dt.hour < heure_ouverture]\n",
    "    else:\n",
    "        donnees_filtrees = df3[(df3['DateTime'].dt.hour >= heure_fermeture) | (df3['DateTime'].dt.hour < heure_ouverture)]\n",
    "\n",
    "\n",
    "    # Calculer la différence entre la consommation réelle et le talon de consommation\n",
    "    donnees_filtrees['Difference'] = donnees_filtrees['Real Consumption (kWh)'] - talon_consommation\n",
    "\n",
    "    # Filtrer les heures de surconsommation (différence > talon_consommation * 0.08)\n",
    "    heures_surconsommation = donnees_filtrees[donnees_filtrees['Difference'] > talon_consommation * 0.08]\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    print(\"l'analyse de site : {}\", code)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Liste des dates uniques dans votre DataFrame\n",
    "    dates_uniques = heures_surconsommation['Date'].unique()\n",
    "\n",
    "    # Parcourir chaque date et effectuer le clustering\n",
    "    for i in range(len(dates_uniques) - 1):\n",
    "        date_actuelle = dates_uniques[i]\n",
    "        date_suivante = dates_uniques[i + 1]\n",
    "\n",
    "        # Filtrer les données pour la date actuelle et la date suivante\n",
    "        heures_nuit = heures_surconsommation[\n",
    "            (heures_surconsommation['Date'] == date_actuelle) &\n",
    "            (heures_surconsommation['DateTime'].dt.hour >= heure_fermeture)\n",
    "        ]\n",
    "\n",
    "        heures_nuit_suivante = heures_surconsommation[\n",
    "            (heures_surconsommation['Date'] == date_suivante) &\n",
    "            (heures_surconsommation['DateTime'].dt.hour < heure_ouverture)\n",
    "        ]\n",
    "\n",
    "\n",
    "        # Combiner les données de la nuit actuelle et de la nuit suivante\n",
    "        if heure_fermeture == 0:\n",
    "            heures_date = heures_nuit_suivante\n",
    "        else:\n",
    "            heures_date = pd.concat([heures_nuit, heures_nuit_suivante])\n",
    "\n",
    "        #print(heures_date.head(10))\n",
    "\n",
    "        # Convertir les colonnes de surconsommation et d'impact en tableaux Numpy\n",
    "        surconsommation = heures_date['DateTime'].values.reshape(-1, 1)\n",
    "        # Extraire les indices et les valeurs de la colonne \"Difference\" des données heures_date\n",
    "        indices = heures_date.index\n",
    "        differences = heures_date['Difference'].values\n",
    "\n",
    "        # Créer le tableau NumPy à partir des indices et des valeurs\n",
    "        impact = np.column_stack((indices, differences))\n",
    "\n",
    "        print(impact)\n",
    "        \n",
    "        if impact.size == 0:\n",
    "             continue\n",
    "        else:\n",
    "            # Créer l'objet DBSCAN\n",
    "            clustering_algo = TimeMarginClustering(time_margin=2, value_margin=marge)\n",
    "\n",
    "\n",
    "            labels = clustering_algo.fit_predict(impact)\n",
    "\n",
    "            # Ajouter les labels de clustering comme une nouvelle colonne\n",
    "            heures_date['Cluster'] = labels\n",
    "\n",
    "            # Calculer la valeur moyenne de l'impact pour chaque cluster\n",
    "            clusters_moyenne = heures_date.groupby('Cluster')['Difference'].mean().reset_index()\n",
    "\n",
    "            # Compter le nombre d'heures regroupées dans chaque cluster\n",
    "            clusters_compte = heures_date.groupby('Cluster')['DateTime'].count().reset_index()\n",
    "            clusters_compte = clusters_compte.rename(columns={'DateTime': 'Nombre d\\'heures regroupées'})\n",
    "\n",
    "            # Fusionner les informations de valeur moyenne et de compte dans un seul DataFrame\n",
    "            clusters_info = clusters_moyenne.merge(clusters_compte, on='Cluster')\n",
    "\n",
    "            #saver dans un excel\n",
    "            for index, row in clusters_info.iterrows():\n",
    "                heuref_list.append(heure_fermeture - 1)\n",
    "                Code_list.append(code)\n",
    "                Energie.append('Electricité')\n",
    "                TalonRef_list.append(talon_consommation)\n",
    "                date1 = dates_uniques[i].to_pydatetime().date()\n",
    "                #date1 = datetime.datetime.strptime(date1, '%Y-%m-%d').date()\n",
    "                Date1_list.append(date1)\n",
    "                date2 = dates_uniques[i + 1].to_pydatetime().date()\n",
    "                #date2 = datetime.datetime.strptime(date2, '%Y-%m-%d').date()\n",
    "                Date2_list.append(date2)\n",
    "                heurev_list.append(heure_ouverture)\n",
    "                NbrHeure_list.append(row['Nombre d\\'heures regroupées'])\n",
    "                defrence_list.append(int(row['Difference']))\n",
    "                surconso_identifie.append(talon_consommation+int(row['Difference']))\n",
    "                Marge_list.append(marge)\n",
    "\n",
    "            # Afficher les informations des clusters pour la date spécifique\n",
    "            print(\"\\n\")\n",
    "            print(f\"Date: {dates_uniques[i]}\")\n",
    "            print(\"\\n\")\n",
    "            print(clusters_info)\n",
    "            print(\"\\n\")\n",
    "          \n",
    "\n",
    "df_NuitOut = pd.DataFrame({'Code':Code_list, 'Energie': Energie,'heure ouverture':heurev_list,'heure fermetur':heuref_list, 'TalonRef':TalonRef_list, 'Début surconsommation':Date1_list, 'Fin surconsommation':Date2_list, 'Talon surconso identifie':surconso_identifie, 'impact':defrence_list,'NbrHeures':NbrHeure_list, 'Marge':Marge_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30072672",
   "metadata": {
    "id": "30072672"
   },
   "source": [
    "# La détection de la surconsommation pour les dimanches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98ae63",
   "metadata": {
    "id": "ee98ae63"
   },
   "source": [
    "# L'appel et l'application de l'algorithme de fusion des heures pour les dimanches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476cb1ad",
   "metadata": {
    "id": "476cb1ad"
   },
   "source": [
    "# L'organisation des sorties dans une feuille d'un fichier Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad8628",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36ad8628",
    "outputId": "b891e411-dfc0-4860-967f-fe793410bfe2"
   },
   "outputs": [],
   "source": [
    "dCode_list=[]\n",
    "dTalonRef_list=[]\n",
    "dDate1_list=[]\n",
    "dDate2_list=[]\n",
    "dheurev_list=[]\n",
    "dheuref_list=[]\n",
    "dNbrHeure_list=[]\n",
    "ddefrence_list=[]\n",
    "dsurconso_identifie=[]\n",
    "dEnergie=[]\n",
    "dNbrNuit=[]\n",
    "Impact_conso = []\n",
    "perSurconso = []\n",
    "Periode = []\n",
    "\n",
    "\n",
    "# Convert 'Date' column to datetime type if needed\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Filter the data to keep only Sundays\n",
    "sundays_data = df[df['Date'].dt.weekday == 6]\n",
    "\n",
    "# Print the filtered data\n",
    "#print(sundays_data.head(30))\n",
    "df = sundays_data\n",
    "for code in df[\"salesforceName\"].unique():\n",
    "    df2 = df[df[\"salesforceName\"] == code]\n",
    "\n",
    "    # Select relevant columns: Date, Time, Real Consumption (kWh), TalonRef, Heure Ouverture, Heure Fermeture, Ouverture dim\n",
    "    df3 = df2[['Date', 'Time', 'Real Consumption (kWh)', 'TalonRef', 'Heure Ouverture', 'Heure Fermeture', 'Ouverture dim' , 'Margin']]\n",
    "\n",
    "    # Convert the 'Date' column to datetime type with the appropriate format\n",
    "    df3['Date'] = pd.to_datetime(df3['Date'], format='%d/%m/%Y')\n",
    "\n",
    "    # Convert the 'Time' column to timedelta type\n",
    "    df3['Time'] = pd.to_timedelta(df3['Time'])\n",
    "\n",
    "    # Combine the 'Date' and 'Time' columns into a single datetime column\n",
    "    df3['DateTime'] = df3['Date'] + df3['Time']\n",
    "\n",
    "    # Define the opening and closing hours of the company\n",
    "    heure_ouverture = df3[\"Heure Ouverture\"].iloc[0]\n",
    "    heure_fermeture = df3[\"Heure Fermeture\"].iloc[0] + 1\n",
    "    ouverture_dim = df3[\"Ouverture dim\"].iloc[0]\n",
    "\n",
    "    # Define the consumption threshold\n",
    "    talon_consommation = df3[\"TalonRef\"].iloc[0]\n",
    "    marge=df3[\"Margin\"].iloc[0]\n",
    "\n",
    "    # Filter the data for hours outside the company's opening hours\n",
    "    if ouverture_dim == \"Journée\":\n",
    "        donnees_filtrees = pd.DataFrame()\n",
    "    elif ouverture_dim == \"Fermé\":\n",
    "        donnees_filtrees = df3[(df3['DateTime'].dt.hour >= heure_ouverture) & (df3['DateTime'].dt.hour < heure_fermeture)]\n",
    "    elif ouverture_dim == \"Matin\":\n",
    "        donnees_filtrees = df3[(df3['DateTime'].dt.hour >= 14) & (df3['DateTime'].dt.hour < heure_fermeture)]\n",
    "\n",
    "    if len(donnees_filtrees) > 0:\n",
    "        # Calculate the difference between the actual consumption and the consumption threshold\n",
    "        donnees_filtrees['Difference'] = donnees_filtrees['Real Consumption (kWh)'] - talon_consommation\n",
    "\n",
    "        # Filter the overconsumption hours (difference > talon_consommation * 0.08)\n",
    "        heures_surconsommation = donnees_filtrees[donnees_filtrees['Difference'] > talon_consommation * 0.08]\n",
    "\n",
    "        # Print the hours of overconsumption\n",
    "        if len(heures_surconsommation) > 0:\n",
    "            print(heures_surconsommation)\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        print(\"l'analyse de site : {}\", code)\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(len(heures_surconsommation))\n",
    "\n",
    "        # Liste des dates uniques dans votre DataFrame\n",
    "        dates_uniques = heures_surconsommation['Date'].unique()\n",
    "        \n",
    "        # Parcourir chaque date et effectuer le clustering\n",
    "        for i in range(len(dates_uniques)-1):\n",
    "            date = dates_uniques[i+1]\n",
    "\n",
    "            heures_date = heures_surconsommation[(heures_surconsommation['Date'] == date)]\n",
    "            #print(heures_date.head(10))\n",
    "\n",
    "            # Convertir les colonnes de surconsommation et d'impact en tableaux Numpy\n",
    "            surconsommation = heures_date['DateTime'].values.reshape(-1, 1)\n",
    "            # Extraire les indices et les valeurs de la colonne \"Difference\" des données heures_date\n",
    "            indices = heures_date.index\n",
    "            differences = heures_date['Difference'].values\n",
    "\n",
    "            # Créer le tableau NumPy à partir des indices et des valeurs\n",
    "            impact = np.column_stack((indices, differences))\n",
    "\n",
    "            \n",
    "            # Créer l'objet DBSCAN\n",
    "            clustering_algo = TimeMarginClustering(time_margin=2, value_margin=marge)\n",
    "\n",
    "            labels = clustering_algo.fit_predict(impact)\n",
    "\n",
    "            # Ajouter les labels de clustering comme une nouvelle colonne\n",
    "            heures_date['Cluster'] = labels\n",
    "\n",
    "            # Calculer la valeur moyenne de l'impact pour chaque cluster\n",
    "            clusters_moyenne = heures_date.groupby('Cluster')['Difference'].mean().reset_index()\n",
    "\n",
    "            # Compter le nombre d'heures regroupées dans chaque cluster\n",
    "            clusters_compte = heures_date.groupby('Cluster')['DateTime'].count().reset_index()\n",
    "            clusters_compte = clusters_compte.rename(columns={'DateTime': 'Nombre d\\'heures regroupées'})\n",
    "\n",
    "            # Fusionner les informations de valeur moyenne et de compte dans un seul DataFrame\n",
    "            clusters_info = clusters_moyenne.merge(clusters_compte, on='Cluster')\n",
    "\n",
    "            #saver dans un excel\n",
    "            for index, row in clusters_info.iterrows():\n",
    "                dheuref_list.append(heure_fermeture - 1)\n",
    "                dCode_list.append(code)\n",
    "                dEnergie.append('Electricité')\n",
    "                dTalonRef_list.append(talon_consommation)\n",
    "                date1 = dates_uniques[i+1].to_pydatetime().date()\n",
    "                dDate1_list.append(date1)\n",
    "               # date_string = np.datetime_as_string(dates_uniques[i+1], unit='D')\n",
    "                #date2 = datetime.datetime.strptime(date_string, '%Y-%m-%d').date()\n",
    "                dDate2_list.append(date1)\n",
    "                dheurev_list.append(heure_ouverture)\n",
    "                dNbrHeure_list.append(row['Nombre d\\'heures regroupées'])\n",
    "                ddefrence_list.append(int(row['Difference']))\n",
    "                dsurconso_identifie.append(arrondir_multiple_de_5(talon_consommation+int(row['Difference'])))\n",
    "                surconso = row['Nombre d\\'heures regroupées'] * int(row['Difference'])\n",
    "                dNbrNuit.append(1)\n",
    "                Impact_conso.append(surconso)\n",
    "\n",
    "                persurconso = (int(row['Difference']) /  talon_consommation)*100\n",
    "                persurconso = int(persurconso)\n",
    "                persurconso = str(persurconso)\n",
    "                persurconso = persurconso + '%'\n",
    "                perSurconso.append(persurconso)\n",
    "                Periode.append('Dim')\n",
    "\n",
    "df_dimOut = pd.DataFrame({'Code':dCode_list, 'Energie': dEnergie,'heure ouverture':dheurev_list,'heure fermetur':dheuref_list, 'TalonRef':dTalonRef_list, 'Début surconsommation':dDate1_list, 'Fin surconsommation':dDate2_list, 'Talon surconso identifie':dsurconso_identifie, 'impact':ddefrence_list,'NbrHeures':dNbrHeure_list, 'NbrNuits':dNbrNuit, 'Impact conso (kWh)':Impact_conso, '% Surconso':perSurconso, \"Période d'alerte\":Periode})\n",
    "grouped_df = df_dimOut.groupby(\"Code\").size().reset_index(name=\"Nombre de lignes\")\n",
    "grouped_df[\"Pourcentage de précision\"] = 100 - (grouped_df[\"Nombre de lignes\"] - 1) * 10\n",
    "df = df_dimOut.merge(grouped_df[[\"Code\", \"Pourcentage de précision\"]], on=\"Code\", how=\"left\")\n",
    "df['Pourcentage de précision'] = df['Pourcentage de précision'].astype(str) + '%'\n",
    "df = process_data(df , 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30bb51",
   "metadata": {},
   "source": [
    "# Prétraitement des données et appel du modèle de machine learning (Random Forest) pour dimanches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5157775",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[[\"Talon surconso identifie\", \"impact\", \"NbrHeures\", \"NbrNuits\", \"Impact conso (kWh)\", \"% Surconso\", \"Période d'alerte\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c66bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113dee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation de la colonne '% Surconso' en float\n",
    "data['% Surconso'] = data['% Surconso'].apply(lambda x: float(x.strip('%')) / 100)\n",
    "\n",
    "# Affichage du dataframe après la transformation\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719668bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un dictionnaire de mapping\n",
    "mapping = {\"Nuit\": 0, \"Dim\": 1, \"Jour\": 2, \"Jour/nuit\": 3, \"Jour/Nuit\": 3}\n",
    "\n",
    "# Remplacer les valeurs de la colonne 'Catégorie' par les entiers correspondants\n",
    "data[\"Période d'alerte\"] = data[\"Période d'alerte\"].replace(mapping)\n",
    "\n",
    "# Afficher les 5 premières lignes du DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d077e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prédictions pour chaque ligne de la dataframe\n",
    "predictions = loaded_model.predict(data)\n",
    "df[\"Catégorie\"] = predictions\n",
    "# Créer un dictionnaire de mapping\n",
    "mapping = {0: \"Investigation en cours\", 1: \"Changement de comportement\", 2: \"Eclairage\", 3: \"Froid\", 4: \"CVC\", 5:\"Multi-usage\"}\n",
    "\n",
    "# Remplacer les valeurs de la colonne 'Catégorie' par les entiers correspondants\n",
    "df['Catégorie'] = df['Catégorie'].replace(mapping)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a013837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(writer, sheet_name='dim', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe1d01",
   "metadata": {
    "id": "e6fe1d01"
   },
   "source": [
    "# Création de l'algorithme de machine learning personnalisé que nous allons utiliser dans la fusion des nuits de surconsommation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d795e",
   "metadata": {
    "id": "935d795e"
   },
   "source": [
    "# Il prend en compte la successivité des dates, une marge de surconsommation et une marge des heures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774c471",
   "metadata": {
    "id": "b774c471"
   },
   "outputs": [],
   "source": [
    "def custom_clustering(X, date_margin, consumption_margin, hours_margin, cond):\n",
    "    clusters = []\n",
    "    remaining_points = X.copy()\n",
    "\n",
    "    while len(remaining_points) > 0:\n",
    "        current_point = remaining_points[0]\n",
    "        cluster = [current_point]\n",
    "        remaining_points = np.delete(remaining_points, 0, axis=0)\n",
    "        i = 0\n",
    "\n",
    "        # Sauvegarde de la valeur originale de date_margin\n",
    "        original_date_margin = date_margin\n",
    "\n",
    "        while i < len(remaining_points):\n",
    "            point = remaining_points[i]\n",
    "\n",
    "\n",
    "            if (abs(point[0] - current_point[0]) <= date_margin and\n",
    "                abs(point[1] - current_point[1]) <= consumption_margin and\n",
    "                abs(point[2] - current_point[2]) <= hours_margin):\n",
    "\n",
    "                current_point = point\n",
    "                cluster.append(point)\n",
    "                remaining_points = np.delete(remaining_points, i, axis=0)\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "            # Vérification de la condition et mise à jour de date_margin si nécessaire\n",
    "            if point[2] >= cond:\n",
    "                date_margin = 1\n",
    "\n",
    "        # Rétablissement de la valeur originale de date_margin\n",
    "        date_margin = original_date_margin\n",
    "\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    return clusters\n",
    "def create_cluster_dataframe(clusters):\n",
    "    cluster_data=[]\n",
    "    for cluster in clusters:\n",
    "        consomption_mean = np.mean([point[1] for point in cluster])\n",
    "        hours_mean = np.mean([point[2] for point in cluster])\n",
    "        count = len(cluster)\n",
    "        cluster_data.append([consomption_mean ,hours_mean , count])\n",
    "    df = pd.DataFrame(cluster_data, columns=['Mean Consomption' , 'Mean Hours', 'Count'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26256a4",
   "metadata": {
    "id": "c26256a4"
   },
   "source": [
    "# L'appel et l'application de l'algorithme de fusion des nuits sur les données output de fusion des heures pour les nuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef1b14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aef1b14",
    "outputId": "3052b56c-9d1c-4911-c43e-7ccd7416ac72"
   },
   "outputs": [],
   "source": [
    "Code_list=[]\n",
    "TalonRef_list=[]\n",
    "Date1_list=[]\n",
    "Date2_list=[]\n",
    "heurev_list=[]\n",
    "heuref_list=[]\n",
    "NbrHeure_list=[]\n",
    "defrence_list=[]\n",
    "surconso_identifie=[]\n",
    "Energie=[]\n",
    "NbrNuit_list=[]\n",
    "NImpact_conso = []\n",
    "NperSurconso = []\n",
    "NPeriode = []\n",
    "\n",
    "\n",
    "\n",
    "for code in df_NuitOut[\"Code\"].unique():\n",
    "    df_Nuit = df_NuitOut[df_NuitOut[\"Code\"] == code]\n",
    "    # Votre code précédent ici...\n",
    "\n",
    "    # Créer un tableau Numpy à partir des colonnes spécifiées\n",
    "    X = np.column_stack((df_Nuit.index, df_Nuit['Talon surconso identifie'], df_Nuit['NbrHeures']))\n",
    "\n",
    "    print(X)\n",
    "    cond = (23 - df_Nuit['heure fermetur'].iloc[0])+df_Nuit['heure ouverture'].iloc[0]\n",
    "    marge=df_Nuit['Marge'].iloc[0]\n",
    "   \n",
    "    clusters = custom_clustering(X , date_margin=2 , consumption_margin=marge , hours_margin=2 , cond=cond)\n",
    "    \n",
    "    df = create_cluster_dataframe(clusters)\n",
    "    print(df.head(5))\n",
    "\n",
    "    for (index, row), cluster in zip(df.iterrows(), clusters):\n",
    "        Energie.append('Electricité')\n",
    "        heuref_list.append(df_Nuit['heure fermetur'].iloc[0])\n",
    "        Code_list.append(code)\n",
    "        TalonRef_list.append(df_Nuit['TalonRef'].iloc[0])\n",
    "        first_index = int(cluster[0][0])\n",
    "        Date1_list.append(df_NuitOut['Début surconsommation'].iloc[first_index])\n",
    "        last_index = int(cluster[-1][0])\n",
    "        Date2_list.append(df_NuitOut['Fin surconsommation'].iloc[last_index])\n",
    "        heurev_list.append(df_Nuit['heure ouverture'].iloc[0])\n",
    "        surconso_identifie.append(arrondir_multiple_de_5(int(row['Mean Consomption'])))\n",
    "        defrence_list.append(int(row['Mean Consomption']) - df_Nuit['TalonRef'].iloc[0])\n",
    "        NbrHeure_list.append(round(row['Mean Hours']))\n",
    "        NbrNuit_list.append(row['Count'])\n",
    "        surconso = round(row['Mean Hours']) * (int(row['Mean Consomption']) - df_Nuit['TalonRef'].iloc[0]) * row['Count']\n",
    "        NImpact_conso.append(surconso)\n",
    "\n",
    "        persurconso = ((int(row['Mean Consomption']) - df_Nuit['TalonRef'].iloc[0]) /  df_Nuit['TalonRef'].iloc[0])*100\n",
    "        persurconso = int(persurconso)\n",
    "        persurconso = str(persurconso)\n",
    "        persurconso = persurconso + '%'\n",
    "        NperSurconso.append(persurconso)\n",
    "        NPeriode.append('Nuit')\n",
    "\n",
    "df_Fusion = pd.DataFrame({'Code':Code_list, 'Energie': Energie,'heure ouverture':heurev_list,'heure fermetur':heuref_list, 'TalonRef':TalonRef_list, 'Début surconsommation':Date1_list, 'Fin surconsommation':Date2_list, 'Talon surconso identifie':surconso_identifie, 'impact':defrence_list,'NbrHeures':NbrHeure_list, 'NbrNuits':NbrNuit_list, 'Impact conso (kWh)':NImpact_conso, '% Surconso':NperSurconso, \"Période d'alerte\":NPeriode})\n",
    "grouped_df = df_Fusion.groupby(\"Code\").size().reset_index(name=\"Nombre de lignes\")\n",
    "grouped_df[\"Pourcentage de précision\"] = np.maximum(30, 100 - (grouped_df[\"Nombre de lignes\"] - 1) * 10)\n",
    "df = df_Fusion.merge(grouped_df[[\"Code\", \"Pourcentage de précision\"]], on=\"Code\", how=\"left\")\n",
    "df['Pourcentage de précision'] = df['Pourcentage de précision'].astype(str) + '%'\n",
    "df = process_data(df , 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0fcb91",
   "metadata": {},
   "source": [
    "# Prétraitement des données et appel du modèle de machine learning (Random Forest) pour nuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3207eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[[\"Talon surconso identifie\", \"impact\", \"NbrHeures\", \"NbrNuits\", \"Impact conso (kWh)\", \"% Surconso\", \"Période d'alerte\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation de la colonne '% Surconso' en float\n",
    "data['% Surconso'] = data['% Surconso'].apply(lambda x: float(x.strip('%')) / 100)\n",
    "\n",
    "# Affichage du dataframe après la transformation\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae539e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un dictionnaire de mapping\n",
    "mapping = {\"Nuit\": 0, \"Dim\": 1, \"Jour\": 2, \"Jour/nuit\": 3, \"Jour/Nuit\": 3}\n",
    "\n",
    "# Remplacer les valeurs de la colonne 'Catégorie' par les entiers correspondants\n",
    "data[\"Période d'alerte\"] = data[\"Période d'alerte\"].replace(mapping)\n",
    "\n",
    "# Afficher les 20 premières lignes du DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prédictions pour chaque ligne de la dataframe\n",
    "predictions = loaded_model.predict(data)\n",
    "df[\"Catégorie\"] = predictions\n",
    "# Créer un dictionnaire de mapping\n",
    "mapping = {0: \"Investigation en cours\", 1: \"Changement de comportement\", 2: \"Eclairage\", 3: \"Froid\", 4: \"CVC\", 5:\"Multi-usage\"}\n",
    "\n",
    "# Remplacer les valeurs de la colonne 'Catégorie' par les entiers correspondants\n",
    "df['Catégorie'] = df['Catégorie'].replace(mapping)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380576d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(writer, sheet_name='Nuit', index=False)\n",
    "print('---------------------------Sauvegarde---------------------------')\n",
    "#writer.save()\n",
    "writer.close()\n",
    "print('---------------------------Fin analyse détection auto---------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ddc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "#df_ref = pd.read_excel('fichier2.xlsx', sheet_name='Conso P60', header=0, skiprows=0)\n",
    "#df_ref.to_csv('data.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "22a377c00d6ce4f589c6dc1fc519227ac8bc24e8fb51bfa08c46f6905c461a5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
